{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis on amazon reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, InputLayer, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src import embedding_helper, data_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "seed = 42\n",
    "\n",
    "embedding_dim = 100\n",
    "max_sequence_length = 100\n",
    "test_size = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_file = 'glove.6B.{}d.txt'.format(embedding_dim)\n",
    "file_name = \"{}reviews.csv\".format(data_dir)\n",
    "texts, scores = data_helper.extract_data(file_name, n_rows=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Erik\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cleaning up the texts by removing stopwords, contractions and unwanted characters\n",
    "texts = data_helper.clean_data(texts, remove_stopwords=True)\n",
    "num_words = data_helper.calc_num_words(texts, threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary for connecting indices with words\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the embedding index and the embedding matrix\n",
    "embeddings_index = embedding_helper.create_embeddings_index(data_dir, embedding_file)\n",
    "embedding_matrix = embedding_helper.create_embedding_matrix(embeddings_index, word_index, num_words, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequence so that they all have the same length. Need for vectorization in Keras\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, scores, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(seed)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(max_sequence_length,), dtype='int32', name=\"input\"))\n",
    "model.add(Embedding(num_words, embedding_dim, weights=[embedding_matrix], trainable=False, name=\"embedded\"))  \n",
    "\n",
    "model.add(LSTM(128, name=\"LSTM_1\"))\n",
    "model.add(Dense(1, activation='sigmoid', name='output'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedded (Embedding)         (None, 100, 100)          6941400   \n",
      "_________________________________________________________________\n",
      "LSTM_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 7,058,777\n",
      "Trainable params: 117,377\n",
      "Non-trainable params: 6,941,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 511608 samples, validate on 56846 samples\n",
      "Epoch 1/5\n",
      "511608/511608 [==============================] - 492s 963us/step - loss: 0.3326 - acc: 0.8558 - val_loss: 0.2915 - val_acc: 0.8741\n",
      "Epoch 2/5\n",
      "511608/511608 [==============================] - 492s 961us/step - loss: 0.2676 - acc: 0.8873 - val_loss: 0.2562 - val_acc: 0.8923\n",
      "Epoch 3/5\n",
      "511608/511608 [==============================] - 502s 980us/step - loss: 0.2389 - acc: 0.9019 - val_loss: 0.2430 - val_acc: 0.9002\n",
      "Epoch 4/5\n",
      "511608/511608 [==============================] - 498s 974us/step - loss: 0.2182 - acc: 0.9118 - val_loss: 0.2271 - val_acc: 0.9086\n",
      "Epoch 5/5\n",
      "511608/511608 [==============================] - 493s 964us/step - loss: 0.2010 - acc: 0.9202 - val_loss: 0.2347 - val_acc: 0.9057\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(seed)\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "learning_rate = 0.0005\n",
    "\n",
    "optimizer = Adam(lr=learning_rate)\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, \n",
    "              validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reversing word_index, i.e. index to word\n",
    "reversed_word_index = dict([(v, k) for k, v in word_index.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: tried couple brands gluten free sandwich cookies best bunch crunchy true texture real cookies gluten free might think filling makes bit sweet means satisfied sweet tooth sooner chocolate version glutino good true chocolatey taste something gluten free brands \n",
      "\n",
      "Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "example = X_val[0,:].reshape((1, max_sequence_length))\n",
    "\n",
    "score = model.predict(example)\n",
    "pred_sentiment = data_helper.sentiment(score)\n",
    "\n",
    "setence = \"\"\n",
    "\n",
    "for i in range(0, example.shape[1]):\n",
    "    if example[0,i] != 0:\n",
    "        setence = setence + \" \" + reversed_word_index[example[0,i]]\n",
    "        \n",
    "print(\"Sentence:{} \\n\".format(setence))\n",
    "print(\"Sentiment: {}\".format(pred_sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: little less expected tends muddy taste expected since said favorite company \n",
      "\n",
      "Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "example = X_val[2,:].reshape((1, max_sequence_length))\n",
    "\n",
    "score = model.predict(example)\n",
    "pred_sentiment = data_helper.sentiment(score)\n",
    "\n",
    "setence = \"\"\n",
    "\n",
    "for i in range(0, example.shape[1]):\n",
    "    if example[0,i] != 0:\n",
    "        setence = setence + \" \" + reversed_word_index[example[0,i]]\n",
    "        \n",
    "print(\"Sentence:{} \\n\".format(setence))\n",
    "print(\"Sentiment: {}\".format(pred_sentiment))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
