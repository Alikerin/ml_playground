{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "pretrained_type = 'bert-base-uncased'\n",
    "seed = 42\n",
    "\n",
    "test_size = 0.1\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH + \"Reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length_sequence = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df[\"Text\"].values.tolist()\n",
    "labels = df[\"Score\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we would like to do positive / negative sentiment prediction we will remove review value 3 since\n",
    "# it can be viewed as neutral\n",
    "\n",
    "text = [text[i] for i in range(len(text)) if labels[i] != 3]\n",
    "labels = np.array([labels[i] for i in range(len(labels)) if labels[i] != 3])\n",
    "labels = (labels > 3).astype(int) # Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-sampling since it would take too long to train otherwise on my computer\n",
    "num_samples = 10000\n",
    "\n",
    "np.random.seed(seed)\n",
    "idx = np.random.choice(np.arange(len(text)), size=num_samples, replace=False)\n",
    "text = [text[i] for i in idx]\n",
    "labels = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train, text_val, labels_train, labels_val = train_test_split(text, labels, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reviews(Dataset):\n",
    "    def __init__(self, text, labels):\n",
    "        self.text = text\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float)\n",
    "        self.len = len(text)\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(pretrained_type)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        txt = BeautifulSoup(self.text[idx]).get_text().lower() \n",
    "        tokens = self.tokenizer.encode(txt, add_special_tokens=True, max_length=max_length_sequence)\n",
    "        tokens = torch.tensor(tokens, dtype=torch.long)\n",
    "        label = self.labels[idx]\n",
    "        return tokens, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    labels = torch.tensor([b[1] for b in batch])\n",
    "\n",
    "    lengths = [len(b[0]) for b in batch]\n",
    "    max_length = min([max(lengths), max_length_sequence])\n",
    "\n",
    "    attention_mask = torch.zeros((len(batch), max_length), dtype=torch.int)\n",
    "    idx_tensor = torch.zeros((len(batch), max_length), dtype=torch.long)\n",
    "\n",
    "    for i in range(len(batch)):\n",
    "        batch_len = lengths[i]\n",
    "        batch_len = min([max_length_sequence, batch_len])\n",
    "\n",
    "        attention_mask[i, 0:batch_len] = 1\n",
    "        idx_tensor[i, 0:batch_len] = batch[i][0][0:batch_len]\n",
    "\n",
    "    return idx_tensor, attention_mask, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 4\n",
    "batch_size = 7\n",
    "\n",
    "train_dataset = Reviews(text_train, labels_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
    "                              num_workers=num_workers, collate_fn=collate_fn)\n",
    "\n",
    "val_dataset = Reviews(text_val, labels_val)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,\n",
    "                              num_workers=num_workers, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, encoder_dim=768):\n",
    "        super().__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(pretrained_type)\n",
    "        self.linear = nn.Linear(encoder_dim, 1)\n",
    "\n",
    "    def forward(self, x, attention_mask):\n",
    "        output = self.bert_model(x, attention_mask=attention_mask)[1]\n",
    "        output = self.linear(output)\n",
    "        return output[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "model = SentimentClassifier()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "lr = 1e-5\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fct = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Epoch 0 -----------\n",
      "Train loss: 0.176774\n",
      "Validation loss: 0.139315\n",
      "Validation accuracy: 0.944888\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "for epoch in range(epochs):\n",
    "    train_loss, val_loss, val_acc = 0.0, 0.0, 0.0\n",
    "\n",
    "    model.train()\n",
    "    for _, (idx_tensor, attention_mask, labels) in enumerate(train_dataloader):\n",
    "        idx_tensor, attention_mask, labels = idx_tensor.to(device), attention_mask.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(idx_tensor, attention_mask)\n",
    "\n",
    "        batch_loss = loss_fct(output, labels)        \n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += batch_loss.detach().cpu().numpy()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for _, (idx_tensor, attention_mask, labels) in enumerate(val_dataloader):\n",
    "            idx_tensor, attention_mask, labels = idx_tensor.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            output = model(idx_tensor, attention_mask)\n",
    "            batch_loss = loss_fct(output, labels)\n",
    "            val_loss += batch_loss.cpu().numpy()\n",
    "\n",
    "            y_hat = (torch.sigmoid(output) > 0.5).long()\n",
    "            batch_acc = (y_hat == labels).float().mean()\n",
    "            val_acc += batch_acc.cpu().numpy()\n",
    "\n",
    "    train_loss = np.round(train_loss / len(train_dataloader), 6)\n",
    "    val_loss = np.round(val_loss / len(val_dataloader), 6)\n",
    "    val_acc = np.round(val_acc / len(val_dataloader), 6)\n",
    "\n",
    "    print(f\"----------- Epoch {epoch} -----------\")\n",
    "    print(f\"Train loss: {train_loss}\")\n",
    "    print(f\"Validation loss: {val_loss}\")\n",
    "    print(f\"Validation accuracy: {val_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
