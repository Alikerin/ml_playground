{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.quantization as quantization\n",
    "\n",
    "from utils.dataset import MNIST\n",
    "from utils.trainer import Trainer\n",
    "from utils.model import MobileNetv2, ConvBnRelu, ConvBn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/digit-recognizer/\"\n",
    "MODEL_FILE = \"data/model.pth\"\n",
    "device = \"cuda\"\n",
    "\n",
    "seed = 42\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH + \"train.csv\")\n",
    "y = df[\"label\"].values\n",
    "X = df.drop(\"label\", axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MNIST(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "test_dataset = MNIST(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 6\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "model = MobileNetv2().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss 0.000991, test loss 0.000259, test accuracy 0.9804\n",
      "Epoch 5: train loss 3e-06, test loss 0.000109, test accuracy 0.992\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, train_loader, test_loader, seed, lr=lr, momentum=0.9, weight_decay=4e-5)\n",
    "\n",
    "for epoch in range(0, n_epochs):\n",
    "    trainer.run_one_epoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model = trainer.model.to(\"cpu\")\n",
    "trainer.device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float accruacy: 0.992\n",
      "CPU times: user 1min 27s, sys: 41.9 s, total: 2min 9s\n",
      "Wall time: 33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_, acc = trainer.validate()\n",
    "print(f\"Float accruacy: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantMobileNet(MobileNetv2):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.quant = quantization.QuantStub()\n",
    "        self.dequant = quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = super().forward(x)        \n",
    "        x = self.dequant(x)\n",
    "        return x\n",
    "\n",
    "    # Fuse Conv+BN and Conv+BN+Relu modules prior to quantization\n",
    "    def fuse_model(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, ConvBnRelu):\n",
    "                torch.quantization.fuse_modules(module, ['conv', 'bn', 'act'], inplace=True)\n",
    "            elif isinstance(module, ConvBn):\n",
    "                torch.quantization.fuse_modules(module, ['conv', 'bn'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per-tensor quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantMobileNet(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBnRelu(\n",
       "      (conv): ConvReLU2d(\n",
       "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (bn): Identity()\n",
       "      (act): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (observer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (2): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (observer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(32, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (observer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (observer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (5): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(64, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=768)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (observer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (6): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): ConvReLU2d(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (observer): Identity()\n",
       "      )\n",
       "    )\n",
       "    (7): ConvBnRelu(\n",
       "      (conv): ConvReLU2d(\n",
       "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (bn): Identity()\n",
       "      (act): Identity()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# min/max range estimation and per-tensor quantization of weights\n",
    "per_tensor_quant_model = QuantMobileNet().to('cpu')\n",
    "_ = per_tensor_quant_model.load_state_dict(torch.load(MODEL_FILE))\n",
    "per_tensor_quant_model.eval()\n",
    "per_tensor_quant_model.fuse_model()\n",
    "per_tensor_quant_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_tensor_quant_model.qconfig = quantization.default_qconfig\n",
    "_ = torch.quantization.prepare(per_tensor_quant_model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_tensor_quant_trainer = Trainer(per_tensor_quant_model, train_loader, test_loader, seed, device=\"cpu\",\n",
    "                        lr=lr, momentum=0.9, weight_decay=4e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrating the model\n",
    "_ = per_tensor_quant_trainer.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/anaconda3/lib/python3.7/site-packages/torch/quantization/observer.py:131: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  Returning default scale and zero point \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantMobileNet(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBnRelu(\n",
       "      (conv): QuantizedConvReLU2d(1, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.055154748260974884, zero_point=0, padding=(1, 1))\n",
       "      (bn): Identity()\n",
       "      (act): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(32, 192, kernel_size=(1, 1), stride=(1, 1), scale=0.08988691121339798, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(192, 192, kernel_size=(3, 3), stride=(2, 2), scale=0.11506599932909012, zero_point=0, padding=(1, 1), groups=192)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.12912055850028992, zero_point=70)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(32, 192, kernel_size=(1, 1), stride=(1, 1), scale=0.0788947120308876, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=0.10184070467948914, zero_point=0, padding=(1, 1), groups=192)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.14582423865795135, zero_point=57)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(32, 384, kernel_size=(1, 1), stride=(1, 1), scale=0.07472240179777145, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(384, 384, kernel_size=(3, 3), stride=(2, 2), scale=0.09906463325023651, zero_point=0, padding=(1, 1), groups=384)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.11621826887130737, zero_point=62)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(64, 384, kernel_size=(1, 1), stride=(1, 1), scale=0.06261251121759415, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(384, 384, kernel_size=(3, 3), stride=(1, 1), scale=0.08555112034082413, zero_point=0, padding=(1, 1), groups=384)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.12570585310459137, zero_point=63)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(64, 768, kernel_size=(1, 1), stride=(1, 1), scale=0.07199200242757797, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(768, 768, kernel_size=(3, 3), stride=(2, 2), scale=0.08115720003843307, zero_point=0, padding=(1, 1), groups=768)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.1246410608291626, zero_point=66)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(128, 768, kernel_size=(1, 1), stride=(1, 1), scale=0.0750902071595192, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(768, 768, kernel_size=(3, 3), stride=(1, 1), scale=0.07366548478603363, zero_point=0, padding=(1, 1), groups=768)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.10731587558984756, zero_point=64)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (7): ConvBnRelu(\n",
       "      (conv): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.038831017911434174, zero_point=0)\n",
       "      (bn): Identity()\n",
       "      (act): Identity()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): QuantizedLinear(in_features=256, out_features=10, scale=0.28433918952941895, zero_point=39)\n",
       "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.quantization.convert(per_tensor_quant_trainer.model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-tensor quant accruacy: 0.9917\n",
      "CPU times: user 10.1 s, sys: 1.51 s, total: 11.6 s\n",
      "Wall time: 3.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_, acc = per_tensor_quant_trainer.validate()\n",
    "print(f\"Per-tensor quant accruacy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel-wise quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_channel_quant_model = QuantMobileNet().to('cpu')\n",
    "_ = per_channel_quant_model.load_state_dict(torch.load(MODEL_FILE))\n",
    "per_channel_quant_model.eval()\n",
    "per_channel_quant_model.fuse_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel-wise quant\n",
    "per_channel_quant_model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "_ = torch.quantization.prepare(per_channel_quant_model, inplace=True)\n",
    "\n",
    "per_channel_quant_trainer = Trainer(per_channel_quant_model, train_loader, test_loader, seed, device=\"cpu\",\n",
    "                                    lr=lr, momentum=0.9, weight_decay=4e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = per_channel_quant_trainer.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/erik/anaconda3/lib/python3.7/site-packages/torch/quantization/observer.py:592: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  Returning default scale and zero point \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "QuantMobileNet(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBnRelu(\n",
       "      (conv): QuantizedConvReLU2d(1, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.04551343992352486, zero_point=0, padding=(1, 1))\n",
       "      (bn): Identity()\n",
       "      (act): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(32, 192, kernel_size=(1, 1), stride=(1, 1), scale=0.05139530077576637, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(192, 192, kernel_size=(3, 3), stride=(2, 2), scale=0.06551120430231094, zero_point=0, padding=(1, 1), groups=192)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.10478436201810837, zero_point=68)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(32, 192, kernel_size=(1, 1), stride=(1, 1), scale=0.05254511162638664, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=0.05395369231700897, zero_point=0, padding=(1, 1), groups=192)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.1008949875831604, zero_point=63)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(32, 384, kernel_size=(1, 1), stride=(1, 1), scale=0.048306867480278015, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(384, 384, kernel_size=(3, 3), stride=(2, 2), scale=0.056014083325862885, zero_point=0, padding=(1, 1), groups=384)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.08182945847511292, zero_point=63)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(64, 384, kernel_size=(1, 1), stride=(1, 1), scale=0.04322953522205353, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(384, 384, kernel_size=(3, 3), stride=(1, 1), scale=0.047997184097766876, zero_point=0, padding=(1, 1), groups=384)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.08138962835073471, zero_point=64)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(64, 768, kernel_size=(1, 1), stride=(1, 1), scale=0.04109308868646622, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(768, 768, kernel_size=(3, 3), stride=(2, 2), scale=0.051674313843250275, zero_point=0, padding=(1, 1), groups=768)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.08636018633842468, zero_point=63)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(128, 768, kernel_size=(1, 1), stride=(1, 1), scale=0.04641806706786156, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(768, 768, kernel_size=(3, 3), stride=(1, 1), scale=0.046256743371486664, zero_point=0, padding=(1, 1), groups=768)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.07760488986968994, zero_point=63)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (7): ConvBnRelu(\n",
       "      (conv): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.030298810452222824, zero_point=0)\n",
       "      (bn): Identity()\n",
       "      (act): Identity()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): QuantizedLinear(in_features=256, out_features=10, scale=0.28239545226097107, zero_point=39)\n",
       "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.quantization.convert(per_channel_quant_trainer.model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-tensor quant accruacy: 0.9919\n",
      "CPU times: user 10.7 s, sys: 1.09 s, total: 11.8 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_, acc = per_channel_quant_trainer.validate()\n",
    "print(f\"Per-tensor quant accruacy: {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization-aware training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_quant_model = QuantMobileNet().to('cpu')\n",
    "_ = aware_quant_model.load_state_dict(torch.load(MODEL_FILE))\n",
    "aware_quant_model.train()\n",
    "aware_quant_model.fuse_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aware_quant_model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "_ = torch.quantization.prepare_qat(aware_quant_model, inplace=True)\n",
    "\n",
    "aware_quant_trainer = Trainer(aware_quant_model, train_loader, test_loader, seed, device=\"cpu\",\n",
    "                              lr=lr / 100, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss 1.5e-05, test loss 0.000108, test accuracy 0.992\n"
     ]
    }
   ],
   "source": [
    "aware_quant_trainer.run_one_epoch(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantMobileNet(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBnRelu(\n",
       "      (conv): QuantizedConvReLU2d(1, 32, kernel_size=(3, 3), stride=(1, 1), scale=0.04378524422645569, zero_point=0, padding=(1, 1))\n",
       "      (bn): Identity()\n",
       "      (act): Identity()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(32, 192, kernel_size=(1, 1), stride=(1, 1), scale=0.04960907623171806, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(192, 192, kernel_size=(3, 3), stride=(2, 2), scale=0.06527788192033768, zero_point=0, padding=(1, 1), groups=192)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.0976630300283432, zero_point=66)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(32, 192, kernel_size=(1, 1), stride=(1, 1), scale=0.052494656294584274, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(192, 192, kernel_size=(3, 3), stride=(1, 1), scale=0.055727895349264145, zero_point=0, padding=(1, 1), groups=192)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), scale=0.10170704871416092, zero_point=63)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(32, 384, kernel_size=(1, 1), stride=(1, 1), scale=0.048359449952840805, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(384, 384, kernel_size=(3, 3), stride=(2, 2), scale=0.05617791786789894, zero_point=0, padding=(1, 1), groups=384)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.0823596641421318, zero_point=63)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(64, 384, kernel_size=(1, 1), stride=(1, 1), scale=0.043603695929050446, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(384, 384, kernel_size=(3, 3), stride=(1, 1), scale=0.04849318787455559, zero_point=0, padding=(1, 1), groups=384)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), scale=0.08233172446489334, zero_point=63)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(64, 768, kernel_size=(1, 1), stride=(1, 1), scale=0.041407011449337006, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(768, 768, kernel_size=(3, 3), stride=(2, 2), scale=0.05234397202730179, zero_point=0, padding=(1, 1), groups=768)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.08783227205276489, zero_point=63)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (bn_layer_1x1_before): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(128, 768, kernel_size=(1, 1), stride=(1, 1), scale=0.0473167859017849, zero_point=0)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_3x3): ConvBnRelu(\n",
       "        (conv): QuantizedConvReLU2d(768, 768, kernel_size=(3, 3), stride=(1, 1), scale=0.04688742011785507, zero_point=0, padding=(1, 1), groups=768)\n",
       "        (bn): Identity()\n",
       "        (act): Identity()\n",
       "      )\n",
       "      (bn_layer_1x1_after): ConvBn(\n",
       "        (conv): QuantizedConv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.07948490977287292, zero_point=63)\n",
       "        (bn): Identity()\n",
       "      )\n",
       "      (skip_add): QFunctional()\n",
       "    )\n",
       "    (7): ConvBnRelu(\n",
       "      (conv): QuantizedConvReLU2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.031240707263350487, zero_point=0)\n",
       "      (bn): Identity()\n",
       "      (act): Identity()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear): QuantizedLinear(in_features=256, out_features=10, scale=0.3323283791542053, zero_point=39)\n",
       "  (quant): Quantize(scale=tensor([0.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aware_quant_trainer.model.eval()\n",
    "quantization.convert(aware_quant_trainer.model, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aware quant accruacy: 0.9922\n",
      "CPU times: user 11 s, sys: 999 ms, total: 12 s\n",
      "Wall time: 3.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_, acc = aware_quant_trainer.validate()\n",
    "print(f\"Aware quant accruacy: {acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
