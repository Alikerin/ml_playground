{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.load(open(\"data/pascal_train2012.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = json_data[\"categories\"]\n",
    "id_cat = []\n",
    "\n",
    "for c in cats:\n",
    "    id_cat.append([c[\"id\"], c[\"name\"]])\n",
    "    \n",
    "df_cats = pd.DataFrame(id_cat, columns=[\"category_id\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cat = {key: value-1 for (value, key) in id_cat}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filename = pd.DataFrame(json_data[\"images\"])\n",
    "df_filename.columns = [\"file_name\", \"height\", \"image_id\", \"width\"]\n",
    "\n",
    "df_bbox = pd.DataFrame(json_data[\"annotations\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_filename.merge(df_bbox, on=\"image_id\")\n",
    "df = df[df[\"ignore\"] == 0]\n",
    "df = df.drop([\"area\", \"ignore\", \"iscrowd\", \"segmentation\", \"image_id\"], axis=1)\n",
    "df = df.merge(df_cats, on=\"category_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>bbox</th>\n",
       "      <th>category_id</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008_000008.jpg</td>\n",
       "      <td>442</td>\n",
       "      <td>500</td>\n",
       "      <td>[52, 86, 419, 334]</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008_000141.jpg</td>\n",
       "      <td>333</td>\n",
       "      <td>500</td>\n",
       "      <td>[93, 8, 407, 325]</td>\n",
       "      <td>13</td>\n",
       "      <td>69</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008_000142.jpg</td>\n",
       "      <td>333</td>\n",
       "      <td>500</td>\n",
       "      <td>[108, 74, 386, 259]</td>\n",
       "      <td>13</td>\n",
       "      <td>71</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008_000371.jpg</td>\n",
       "      <td>333</td>\n",
       "      <td>500</td>\n",
       "      <td>[188, 128, 186, 148]</td>\n",
       "      <td>13</td>\n",
       "      <td>229</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008_000428.jpg</td>\n",
       "      <td>253</td>\n",
       "      <td>400</td>\n",
       "      <td>[0, 42, 378, 195]</td>\n",
       "      <td>13</td>\n",
       "      <td>276</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         file_name  height  width                  bbox  category_id   id  \\\n",
       "0  2008_000008.jpg     442    500    [52, 86, 419, 334]           13    1   \n",
       "1  2008_000141.jpg     333    500     [93, 8, 407, 325]           13   69   \n",
       "2  2008_000142.jpg     333    500   [108, 74, 386, 259]           13   71   \n",
       "3  2008_000371.jpg     333    500  [188, 128, 186, 148]           13  229   \n",
       "4  2008_000428.jpg     253    400     [0, 42, 378, 195]           13  276   \n",
       "\n",
       "    name  \n",
       "0  horse  \n",
       "1  horse  \n",
       "2  horse  \n",
       "3  horse  \n",
       "4  horse  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2008_000008.jpg', 500, 442, ['horse', 'person'], [[52, 86, 419, 334], [157, 43, 132, 124]], [12, 14]]\n"
     ]
    }
   ],
   "source": [
    "grouped_data = []\n",
    "\n",
    "grouped = df.groupby(\"file_name\")\n",
    "for name, group in grouped:\n",
    "    val = [name, group[\"width\"].values[0], group[\"height\"].values[0], list(group[\"name\"].values),\n",
    "           list(group[\"bbox\"].values), list(group[\"category_id\"].values - 1)]\n",
    "    grouped_data.append(val)\n",
    "    \n",
    "print(grouped_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = 224\n",
    "\n",
    "for g in grouped_data:\n",
    "    x_scale = target_size / g[1]\n",
    "    y_scale = target_size / g[2]\n",
    "\n",
    "    old_boxes = g[4]\n",
    "    new_boxes = []\n",
    "\n",
    "    for i in range(len(old_boxes)):\n",
    "        (x, y, d_x, d_y) = old_boxes[i]\n",
    "\n",
    "        x = int(round(x * x_scale))\n",
    "        y = int(round(y * y_scale))\n",
    "        d_x = int(round(d_x * x_scale))\n",
    "        d_y = int(round(d_y * y_scale))\n",
    "    \n",
    "        new_boxes.append([x, y, d_x, d_y])\n",
    "        \n",
    "    g[4] = new_boxes\n",
    "    \n",
    "    # removing width and height\n",
    "    del g[2]\n",
    "    del g[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2008_000019.jpg',\n",
       " ['dog', 'dog', 'dog'],\n",
       " [[64, 1, 109, 161], [77, 54, 72, 141], [168, 0, 56, 92]],\n",
       " [11, 11, 11]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = grouped_data[2]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(boxes, image):\n",
    "    for i in range(len(boxes)):\n",
    "        cv2.rectangle(image, (boxes[i][0], boxes[i][1]),\n",
    "                      (boxes[i][0] + boxes[i][2], boxes[i][1] + boxes[i][3]), (255, 0, 0), 1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "img_str = path + example[0]\n",
    "\n",
    "img = cv2.imread(img_str, cv2.IMREAD_UNCHANGED)\n",
    "img = cv2.resize(img, (target_size, target_size))\n",
    "\n",
    "img = draw_boxes(example[2], img)\n",
    "#cv2.imshow(\"img\", img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 2\n",
    "C = 20\n",
    "S = 7\n",
    "grid_size = target_size / S\n",
    "\n",
    "y_list = []\n",
    "cc = 0\n",
    "\n",
    "for data in grouped_data:\n",
    "\n",
    "    # OLD!!! For one grid element: [pc, bx, by, w, h, c1, ..., cN]\n",
    "    # NEW!!! For one grid element: [pc, c1, ..., cN, b1x, b1y, w1, h1, b2x, b2y, w2, h2]\n",
    "    \n",
    "    y = np.zeros((1, S, S, 5*B + C))\n",
    "\n",
    "    boxes = data[2]\n",
    "    classes = data[3]\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        box = boxes[i]\n",
    "\n",
    "        center_width = box[0] + box[2]/2\n",
    "        center_height = box[1] + box[3]/2\n",
    "\n",
    "        width_index = int(np.floor((center_width / target_size) * S))\n",
    "        height_index = int(np.floor((center_height / target_size) * S))\n",
    "\n",
    "        class_index = classes[i]\n",
    "\n",
    "        # Normalize width and height by the enitre image size\n",
    "        w = box[2] / target_size\n",
    "        h = box[3] / target_size\n",
    "\n",
    "        # Normalize bx and by according to the current grid position\n",
    "        bx = (center_width - ((width_index / S) * target_size)) / grid_size\n",
    "        by = (center_height - ((height_index / S) * target_size)) / grid_size\n",
    "\n",
    "        \n",
    "        y[:, width_index, height_index, class_index] = 1.0\n",
    "        \n",
    "        # Hardcoded for B=2\n",
    "        if y[:, width_index, height_index, 20] == 0.0:\n",
    "            y[:, width_index, height_index, 20] = 1.0\n",
    "            y[:, width_index, height_index, 21] = bx\n",
    "            y[:, width_index, height_index, 22] = by\n",
    "            y[:, width_index, height_index, 23] = w\n",
    "            y[:, width_index, height_index, 24] = h\n",
    "        else:\n",
    "            y[:, width_index, height_index, 25] = 1.0\n",
    "            y[:, width_index, height_index, 26] = bx\n",
    "            y[:, width_index, height_index, 27] = by\n",
    "            y[:, width_index, height_index, 28] = w\n",
    "            y[:, width_index, height_index, 29] = h\n",
    "\n",
    "    y_list.append(y)\n",
    "y = np.concatenate(y_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Removing adaptive avg pooling and fc\n",
    "        pretrained_model = list(models.resnet34(pretrained='imagenet').children())[:-2]\n",
    "        self.pretrained_model = nn.Sequential(*pretrained_model)\n",
    "        \n",
    "        self.fc_1 = nn.Linear(512*7*7, 4096)\n",
    "        self.fc_out = nn.Linear(4096, S*S*(5*B + C))\n",
    "                              \n",
    "    def forward(self, x):\n",
    "        x = self.pretrained_model(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc_out(x)\n",
    "        x = x.view(x.size(0), S, S, (5*B + C))\n",
    "        x = F.relu(x)\n",
    "        return x\n",
    "    \n",
    "    def change_freezing(self, mode=False):\n",
    "        for param in self.pretrained_model.parameters():\n",
    "            param.requires_grad = mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "model = Model()\n",
    "model = model.to(device)\n",
    "model.change_freezing(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PascalData(Dataset):\n",
    "    def __init__(self, data_list, y, lambda_indicator, target_size=target_size, path=path):\n",
    "        self.target_size = target_size\n",
    "        self.path = path\n",
    "        \n",
    "        self.lambda_indicator = torch.from_numpy(lambda_indicator).float().to(device)\n",
    "        \n",
    "        self.y = torch.from_numpy(y).float().to(device)\n",
    "        self.file_list = [i[0] for i in data_list]      \n",
    "        \n",
    "        self.mean = np.array([0.485, 0.456, 0.406]).reshape((1,1,3))\n",
    "        self.std = np.array([0.229, 0.224, 0.225]).reshape((1,1,3))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_str = self.path + self.file_list[idx]\n",
    "\n",
    "        img = cv2.imread(img_str, cv2.IMREAD_UNCHANGED)\n",
    "        img = cv2.resize(img, (self.target_size, self.target_size))\n",
    "        img = img / 255.0\n",
    "        img = (img - self.mean) / self.std\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        img = torch.from_numpy(img).float().to(device)\n",
    "        return (img, self.y[idx,:], self.lambda_indicator[idx, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_coord = 5\n",
    "lambda_noobj = 0.5\n",
    "\n",
    "lambda_indicator = (y > 0.0).astype(float)\n",
    "\n",
    "lambda_indicator[:, :, :, 0:20][(lambda_indicator[:, :, :, 20] != 0.0) | \n",
    "                                (lambda_indicator[:, :, :, 25] != 0.0)] = 1.0\n",
    "\n",
    "lambda_indicator[:, :, :, 20][lambda_indicator[:, :, :, 20] == 0.0] = lambda_noobj\n",
    "lambda_indicator[:, :, :, 21] = lambda_indicator[:, :, :, 21]*lambda_coord\n",
    "lambda_indicator[:, :, :, 22] = lambda_indicator[:, :, :, 22]*lambda_coord\n",
    "lambda_indicator[:, :, :, 23] = lambda_indicator[:, :, :, 23]*lambda_coord\n",
    "lambda_indicator[:, :, :, 24] = lambda_indicator[:, :, :, 24]*lambda_coord\n",
    "\n",
    "lambda_indicator[:, :, :, 25][lambda_indicator[:, :, :, 20] == 0.5] = lambda_noobj\n",
    "lambda_indicator[:, :, :, 26] = lambda_indicator[:, :, :, 26]*lambda_coord\n",
    "lambda_indicator[:, :, :, 27] = lambda_indicator[:, :, :, 27]*lambda_coord\n",
    "lambda_indicator[:, :, :, 28] = lambda_indicator[:, :, :, 28]*lambda_coord\n",
    "lambda_indicator[:, :, :, 29] = lambda_indicator[:, :, :, 29]*lambda_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataset = PascalData(grouped_data, y, lambda_indicator)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(y, y_hat, indicator):\n",
    "    y[:,:,:,23] = torch.sqrt(y[:,:,:,23])\n",
    "    y[:,:,:,24] = torch.sqrt(y[:,:,:,24])\n",
    "    y[:,:,:,28] = torch.sqrt(y[:,:,:,28])\n",
    "    y[:,:,:,29] = torch.sqrt(y[:,:,:,29])\n",
    "    \n",
    "    y_hat[:,:,:,23] = torch.sqrt(y_hat[:,:,:,23])\n",
    "    y_hat[:,:,:,24] = torch.sqrt(y_hat[:,:,:,24])\n",
    "    y_hat[:,:,:,28] = torch.sqrt(y_hat[:,:,:,28])\n",
    "    y_hat[:,:,:,29] = torch.sqrt(y_hat[:,:,:,29])\n",
    "    \n",
    "    return torch.sum(indicator * ((y - y_hat)*(y - y_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "n_epochs = 15\n",
    "lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.535625\n",
      "7.15091\n",
      "5.919106\n",
      "5.037757\n",
      "4.533224\n",
      "4.137744\n",
      "3.830325\n",
      "3.613034\n",
      "3.536706\n",
      "3.341004\n",
      "3.252924\n",
      "3.127773\n",
      "3.060486\n",
      "3.032904\n",
      "3.07592\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(seed)\n",
    "for epoch in range(0, n_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for _, (x_i, y_i, indicator_i) in enumerate(train_loader):\n",
    "        model.zero_grad()\n",
    "        y_hat = model(x_i)\n",
    "        batch_loss = loss(y_i, y_hat, indicator_i)\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += batch_loss / batch_size\n",
    "    train_loss = np.round((train_loss/len(train_loader)).detach().cpu().numpy(), 6)\n",
    "    print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 14\n",
    "(x_i, _, _) = dataset[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(x_i.reshape(1, 3, 224, 224))\n",
    "y_hat = y_hat.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_bb = []\n",
    "class_list = []\n",
    "\n",
    "pc_threshold = 0.4\n",
    "\n",
    "for i in range(S):\n",
    "    for j in range(S):\n",
    "        for b in range(B):\n",
    "            pc = y_hat[:, i, j, 20 + 5*b]\n",
    "\n",
    "            if pc < pc_threshold:\n",
    "                continue\n",
    "        \n",
    "            box_width = y_hat[:, i, j, 21 + 5*b]*target_size\n",
    "            box_height = y_hat[:, i, j, 22 + 5*b]*target_size\n",
    "\n",
    "            bx = i*grid_size + y_hat[:, i, j, 23 + 5*b]*grid_size - box_width/2\n",
    "            by = j*grid_size + y_hat[:, i, j, 24 + 5*b]*grid_size - box_height/2            \n",
    "            \n",
    "            output_bb.append([pc[0], bx[0], by[0], box_width[0], box_height[0]])\n",
    "            \n",
    "        classes_predict = np.argwhere(y_hat[:, i, j, 0:20][0,:] > 0.5)\n",
    "        \n",
    "        if len(classes_predict) > 0:\n",
    "            class_list.append(classes_predict[0])\n",
    "        \n",
    "#output_bb = sorted(output_bb, key = lambda x: x[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([14], dtype=int64),\n",
       " array([8], dtype=int64),\n",
       " array([14], dtype=int64),\n",
       " array([14], dtype=int64),\n",
       " array([14], dtype=int64),\n",
       " array([8], dtype=int64)]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[77.78871, 82.65389, 80.22976, 76.03548],\n",
       " [97.875946, 105.96737, 155.80215, 125.462296]]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[bb[1:] for bb in output_bb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = dataset.file_list[index]\n",
    "img_str = path + img_file\n",
    "\n",
    "target_size = 224\n",
    "img = cv2.imread(img_str, cv2.IMREAD_UNCHANGED)\n",
    "img = cv2.resize(img, (target_size, target_size))\n",
    "\n",
    "img = draw_boxes([bb[1:] for bb in output_bb], img)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aeroplane': 0,\n",
       " 'bicycle': 1,\n",
       " 'bird': 2,\n",
       " 'boat': 3,\n",
       " 'bottle': 4,\n",
       " 'bus': 5,\n",
       " 'car': 6,\n",
       " 'cat': 7,\n",
       " 'chair': 8,\n",
       " 'cow': 9,\n",
       " 'diningtable': 10,\n",
       " 'dog': 11,\n",
       " 'horse': 12,\n",
       " 'motorbike': 13,\n",
       " 'person': 14,\n",
       " 'pottedplant': 15,\n",
       " 'sheep': 16,\n",
       " 'sofa': 17,\n",
       " 'train': 18,\n",
       " 'tvmonitor': 19}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_bb = []\n",
    "predicted_bb.append(output_bb[0])\n",
    "_ = output_bb.pop(0)\n",
    "\n",
    "while len(output_bb) != 0:\n",
    "    predicted_bb.append(output_bb[0])\n",
    "    _ = output_bb.pop(0)\n",
    "    \n",
    "    for accepted_bb in predicted_bb:\n",
    "        filter(lambda x: bb_intersection_over_union(accepted_bb[2:], x[2:]) < 0.5, output_bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = grouped_data[4]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    boxA[2] = boxA[2] + boxA[0]\n",
    "    boxA[3] = boxA[3] + boxA[1]\n",
    "    \n",
    "    boxB[2] = boxB[2] + boxB[0]\n",
    "    boxB[3] = boxB[3] + boxB[1]\n",
    "    \n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    " \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    " \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    " \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    " \n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = example[2][0]\n",
    "b = example[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_intersection_over_union(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_str = path + example[0]\n",
    "\n",
    "target_size = 224\n",
    "img = cv2.imread(img_str, cv2.IMREAD_UNCHANGED)\n",
    "img = cv2.resize(img, (target_size, target_size))\n",
    "\n",
    "img = draw_boxes(example[2], img)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou = 0.4\n",
    "iou < 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(a, b, epsilon=1e-5):\n",
    "    \"\"\" Given two boxes `a` and `b` defined as a list of four numbers:\n",
    "            [x1,y1,x2,y2]\n",
    "        where:\n",
    "            x1,y1 represent the upper left corner\n",
    "            x2,y2 represent the lower right corner\n",
    "        It returns the Intersect of Union score for these two boxes.\n",
    "\n",
    "    Args:\n",
    "        a:          (list of 4 numbers) [x1,y1,x2,y2]\n",
    "        b:          (list of 4 numbers) [x1,y1,x2,y2]\n",
    "        epsilon:    (float) Small value to prevent division by zero\n",
    "\n",
    "    Returns:\n",
    "        (float) The Intersect of Union score.\n",
    "    \"\"\"\n",
    "    \n",
    "    a[2] = a[2] + a[0]\n",
    "    a[3] = a[3] + a[1]\n",
    "    \n",
    "    b[2] = b[2] + b[0]\n",
    "    b[3] = b[3] + b[1]\n",
    "\n",
    "    \n",
    "    # COORDINATES OF THE INTERSECTION BOX\n",
    "    x1 = max(a[0], b[0])\n",
    "    y1 = max(a[1], b[1])\n",
    "    x2 = min(a[2], b[2])\n",
    "    y2 = min(a[3], b[3])\n",
    "\n",
    "    # AREA OF OVERLAP - Area where the boxes intersect\n",
    "    width = (x2 - x1)\n",
    "    height = (y2 - y1)\n",
    "    # handle case where there is NO overlap\n",
    "    if (width<0) or (height <0):\n",
    "        return 0.0\n",
    "    area_overlap = width * height\n",
    "\n",
    "    # COMBINED AREA\n",
    "    area_a = (a[2] - a[0]) * (a[3] - a[1])\n",
    "    area_b = (b[2] - b[0]) * (b[3] - b[1])\n",
    "    area_combined = area_a + area_b - area_overlap\n",
    "\n",
    "    # RATIO OF AREA OF OVERLAP OVER COMBINED AREA\n",
    "    iou = area_overlap / (area_combined+epsilon)\n",
    "    print(iou)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = dataset.file_list[0]\n",
    "img_str = path + img_file\n",
    "\n",
    "target_size = 224\n",
    "img = cv2.imread(img_str, cv2.IMREAD_UNCHANGED)\n",
    "img = cv2.resize(img, (target_size, target_size))\n",
    "\n",
    "img = draw_boxes(predicted_bb[0:2][2:], img)\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(boxes, image):\n",
    "    for i in range(len(boxes)):\n",
    "        cv2.rectangle(image, (boxes[i][0], boxes[i][1]),\n",
    "                      (boxes[i][0] + boxes[i][2], boxes[i][1] + boxes[i][3]), (255, 0, 0), 1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "def draw_grid(img, line_color=(0, 255, 0), thickness=1, type_=cv2.LINE_AA, pxstep=50):\n",
    "    '''(ndarray, 3-tuple, int, int) -> void\n",
    "    draw gridlines on img\n",
    "    line_color:\n",
    "        BGR representation of colour\n",
    "    thickness:\n",
    "        line thickness\n",
    "    type:\n",
    "        8, 4 or cv2.LINE_AA\n",
    "    pxstep:\n",
    "        grid line frequency in pixels\n",
    "    '''\n",
    "    \n",
    "    x = pxstep\n",
    "    y = pxstep\n",
    "    while x < img.shape[1]:\n",
    "        cv2.line(img, (x, 0), (x, img.shape[0]), color=line_color, lineType=type_, thickness=thickness)\n",
    "        x += pxstep\n",
    "\n",
    "    while y < img.shape[0]:\n",
    "        cv2.line(img, (0, y), (img.shape[1], y), color=line_color, lineType=type_, thickness=thickness)\n",
    "        y += pxstep   \n",
    "        \n",
    "    return img\n",
    "    \n",
    "#example = grouped_data[0]\n",
    "img_str = path + example[0]\n",
    "\n",
    "target_size = 224\n",
    "img = cv2.imread(img_str, cv2.IMREAD_UNCHANGED)\n",
    "img = cv2.resize(img, (target_size, target_size))\n",
    "\n",
    "img = draw_boxes(example[2], img)\n",
    "img = draw_grid(img, line_color=(0, 255, 0), thickness=1, type_=cv2.LINE_AA, pxstep=int(target_size / S))\n",
    "img = cv2.circle(img, (int(center_width), int(center_height)), 5, (255, 255, 255), -1)\n",
    "\n",
    "#cv2.imshow(\"img\", img)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
